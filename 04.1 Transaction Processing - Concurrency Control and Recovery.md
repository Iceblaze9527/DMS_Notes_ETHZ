---
tags: DMS
---

# 04.1 Transaction Processing - Concurrency Control and Recovery
[TOC]

## 1. ACID
- **Atomicity:** the notion that an operation or a group of operations must take place in their entirety or not at all
- **Consistency:** operations should take the database from a correct state to another correct state
- **Isolation:** concurrent execution of operations should yield results that are predictable and correct
- **Durability:** the database needs to remember the state it is in at all moments, even when failures occur

### 1.1 Consistency
- **Database State:** The actual values stored in a database at a given point in time (both in memory as well as in storage)
- **Consistent State:** A database state that is the result of correctly applying operations to the database
- **Sequentiality:** In databases, the underlying model of correct execution of operations is sequential execution: all operations are executed one after each other with no concurrency
- **Transactions:** We assume that transactions are correct. The database has mechanisms to prevent incorrect data modifications.

### 1.2 Atomicity
Only a transaction executed in its entirety brings the database from a consistent state to another consistent state. Intermediate results cannot be assumed to be correct.

If a transaction does not complete, we need to make sure that either:
- **Undo:** The initial state is restored and any effects of the transaction are removed
- **Redo:** The intended final state is reached

#### Atomicity requires isolation
If a transaction can see the intermediate state created by another transaction, its input is not guaranteed to be consistent and, thus the output is not guaranteed to be consistent.

### 1.3 Isolation
Transactions are executed in a database as if they were alone in the database and nothing else would be running at the same time
- Transactions should not see the intermediate state of other transactions
- Queries should not see the intermediate state of transactions

The consequences of enforcing isolation:
- We need to be able to determine when a transaction is done with its changes so that they become visible
- We need to detect conflicts (operations one the same data that will result in intermediate results being visible)
- In case of conflicts, we need to have mechanisms to resolve them or prevent them

#### Concurrency Control and Locking
Isolation in databases is enforced through concurrency control mechanisms
- Prevent conflicts
- Ensure a level of consistency by controlling what can be seen of a transaction

The canonical concurrency control mechanism in databases is locking
- Use locks to prevent conflicting accesses
- Use locking policies to ensure transactions are isolated

### 1.4 Durability
Durability ensures that the changes of a completed transaction are remembered by the system and can be recovered

:::info
**Note:** write to the **memory** of all machines (but eventually you write to disk, but you need to decide when)
:::

#### Recovery and the Log
The log and the snapshots allow to go back and forward in the history of the database by undoing or redoing transactions from a given snapshot
- The transaction history is captured in the database log
- The consistent database state at a given point in time is captured in snapshots

#### Small Warning
Often, concurrency control and recovery are treated as separate problems

In reality, they are deeply interrelated both at the theoretical as well as at the practical, implementation level

## 2. Transaction Model
### 2.1 Defining a Transaction
- Begin of transaction (BOT): often implicit
- **Commit:** transaction has finished, database confirms to client when all changes of the transaction have been made persistent
- **Abort/rollback:** transaction is cancelled, database rollbacks all (part of the) changes done by the transaction
- **Read:** read a data item
- **Write:** write a data item
- **a $<_T$ b:** a happens before b, partial order; implies a will be done before b

### 2.2 Transactions in Real Systems
- `COMMIT` = indicates the transaction will not do any more changes and all the changes made must be made persistent and durable: The database engine will confirm the commit only after it is sure the changes are persistent and/or have been recorded
- `ROLLBACK` = indicates that the transaction is being cancelled and all of its changes must be removed from the system
- `SAVEPOINTS` = allow to temporarily commit the changes made by a transaction up to the savepoint
- `ROLLBACK TO SAVEPOINT` = allows to cancel all the changes made by a transaction after the indicated savepoint, bringing the state seen by the transaction to that of the savepoint

### 2.3 Transaction Operations
- **Read Operations:** represent access to a tuple without modifying it:`r1[x]`
- **Write Operations:** represent access to a tuple that change the value of the tuple: `w1[y]`
- **Conflicting Operations:** two operations over the same item with one of them being a write

### 2.4 Histories
A history H is a partial ordered ($<_H$) sequence of operations from a set of transactions where
- If two operations are ordered within a transaction, they are equally ordered in the history
- If two operations, p and q, conflict then they are ordered with respect to each other: $p<_H q$ or $q<_H p$

![](https://hackmd.io/_uploads/HydlNtXDs.png =600x)

## 3. Concurrency Control
Concurrency control has the goal of ensuring correct executions of concurrent transactions
- Define a baseline for correctness (serial execution)
- Define equivalence between histories
- Define correct histories as those equivalent to serial histories

### 3.1 Serial History
A history H is serial if, for every two transactions $T_i$ and $T_j$ that appear in H, either all operations from $T_j$ appear before all operations of $T_j$ or viceversa.

A serial history with only committed transactions is correct by definition.

### 3.2 Equivalent Histories
Two histories are equivalent iff
1. They are over the same transactions and contain the same operations
2. Conflicting operations of non-aborted transactions are ordered in the same way in both histories

History equivalence captures the fact that, in the two histories, committed transactions see the same state (read the same values) and leave the database in the same state.

![](https://hackmd.io/_uploads/BJoiIY7ws.png =600x)

### 3.3 Serializable History
A history is serializable iff it is equivalent to a serial history.

![](https://hackmd.io/_uploads/r1tycKXws.png =600x)

### 3.4 Serializability Graph
![](https://hackmd.io/_uploads/rk0d5Kmvs.png =300x)

- Compact representation of the dependencies in a history.
- If the graph is acyclic, a topological sort gives an equivalent serial history

### 3.5 Serializability Theorem
A history is serializable iff its serializability graph is acyclic.

![](https://hackmd.io/_uploads/H1ilsYmvo.png =600x)

### 3.6 Summary
- A history captures the execution of transactions over the database
- A history is correct if it is serializable (equivalent to a serial history)
- Serializability is the canonical correctness criterion for databases
- Serializability is not complete, it does not cover a number of important cases that appear when the level of abstraction is lowered (operations, items being updated, tables, inserts and deletes, etc.)
- It also does not cover the case when transactions are still active

## 4. Recovery
Recovery has the aim to make sure that, even in the case of failures, the changes from transactions that have not completed are not visible and those of committed transactions are recorded and visible
- Define undesirable situations
- Classify histories according these situations
- Define how histories can avoid such situations

Covers conflict cases when transactions are still active
- Recoverable
- Avoids Cascading Aborts
- Strict

### 4.1 R1-R4: Recovery procedures
1. Abort/Rollback of a single transaction (regardless of why)
- **R1:** Undo all changes from the transaction

2. System crash: lose main memory, keep disk
- **R2:** Redo the changes from committed transactions
- **R3:** Undo the changes that remain in the system from active transactions

3. System crash with loss of disks
- **R4:** Read consistent snapshot form backup, if available, apply log

### 4.2 Implication of Procedures
We can undo the changes of an active transaction
- We need to keep a copy of the value before it was modified
- Shadow pages is a mechanism that would support this

We can redo the changes made by committed transactions
- We need to keep a persistent record of all the changes made by committed transactions
- This is why there is a redo log

We have a consistent snapshot to start with
- Either move forward by taking a snapshot and apply committed transactions
- Or move backward by taking the current state and go back to a consistent state by undoing changes from transactions that should not be there

### 4.3 Undo - Redo
Databases log transactions by keeping before and after images of their changes
- The changes of an aborted transaction are undone: Typically by restoring the before image of the value modified
- The changes of a committed transaction can be redone: Typically by restoring the after image of the value modified

### 4.4 Recovery on Histories
A transaction $T_1$ reads from another transaction $T_2$ if $T_1$ reads a value written by $T_2$ at a time when $T_2$ was not aborted: `w2[x], r1[x]`

#### Recoverable (RC) History 
:::info
If $T_i$ reads from $T_j$ and commits, then `cj < ci`
:::

- wrong: `w2[x], r1[x], c1, a2` ($T_1$ has read invalid data, Since $T_1$ committed, the data has been returned to the user)
- correct: `w2[x], r1[x], c2, c1`

Recovery now involves correcting the application that has processed the data and might have acted upon it => typically a very expensive procedure

It is avoided by making sure that $T_1$ does not commit until $T_2$ commits, if $T_2$ aborts, then we can safely abort $T_1$ since the results have not been returned to the user

Result:
- No need to undo a committed transaction because it read the wrong data
- Transactions commit in their serialization order

#### Avoids Cascading Aborts (ACA) History
:::info
If $T_i$ reads `x` from $T_j$, then `cj < ri[x]`
:::

read something uncommitted would result in cascading aborts
- wrong: `w2[x], r1[x]` -> When $T_2$ aborts, we have to abort $T_1$ because it has read invalid data (the change made by $T_2$ which will be undone as part of the rollback of $T_2$)
- correct: `w2[x], c2, r1[x]`

If cascading of aborts happen very often, performance will suffer since aborting one transaction results in other transactions or queries being aborted

It is avoided by making sure that uncommitted data is never read

Result:
- Aborting a transaction does not cause aborting others
- Transactions only read from committed transactions

#### Strict (ST) History
:::info
If $T_i$ reads from or overwrites a value written by $T_j$, then `cj < ri[x]/wi[x]` or `aj < ri[x]/wi[x]`
:::
- wrong: `w2[x], w1[x], a2`

Undoing $T_2$ implies aborting $T_1$: If we undo `w2[x]`, then we also remove the changes made by $T_1$. This is because undoing changes is done by restoring the before image and the before image for `w2` does not include the change made by `w1`.

Like in ACA, non-strict execution leads to cascading aborts of transactions that update the same item which affects performance. It is avoided by not letting a value to be read or updated unless it is committed

Result:
- Undoing a transaction does not undo the changes of other transactions
- Transactions do not read or overwrite updates of uncommitted transactions

### 4.5 Recoverability Matters
#### Not RC
I run my program, get some data, finish the program and issue a report. The data read was later removed because another program aborted

#### Not ACA
Thrashing behavior when transactions keep aborting each other (my program makes no progress because of other programs)

#### Not Strict
Recovery after a failure becomes very complex (or impossible)

## 5. Putting All Together
![](https://hackmd.io/_uploads/SyEiM2QDo.png =400x)

### 5.1 ANSI isolation levels
SQL standardized the isolation levels but it did it in a different way than what we have just explained.

The way SQL defines these levels is problematic (and has generated decades of controversy)
- Consistency levels provided by each system varies slightly
- Some corner cases become difficult

The SQL standard is too vague and focus solely on isolation not recovery

These days, no longer controversial, only two approaches: locking and snapshot isolation with the differences well understood

### 5.2 Three SQL “Phenomena”
Note that the phenomena considered do not include write-write conflicts

#### Dirty Read `w1[x],r2[x]`
- Occurs when uncommitted data is read
- Dirty reads result in non-ACA histories
- can be recoverable and unrecoverable

#### Non-repeatable Read `r2[x],w1[x],r2[x]`
- Occurs when a transaction reads the same item at different times and sees different values each time
- It is the result of somebody else updating the item concurrently
- Non-repeatable reads correspond to a non-serializable execution

#### Phantom Reads
![](https://hackmd.io/_uploads/r19xVhmDj.png =400x)

Occur when a tuple is inserted or deleted on a table:
- An aggregate over the table will be different before and after the insert/delete
- Not a conflict in the formal sense

It is not necessarily a repeatable read problem

This is a conflict at the table level (a change to the table rather than a tuple)

### 5.3 SQL Isolation Levels
![](https://hackmd.io/_uploads/ByUeHhQPi.png =600x)

- Why this? locking consideration
- These criteria are not comparable

#### Read Uncommitted
- Used when the operation does not affect reads (or doesn’t matter)
- It is not ACA and it allows non-recoverable executions

#### Read Committed
- It is recoverable but it might not be ACA or serializable

#### Repeatable Read
- It is ACA but might not be serializable or strict

#### Serializable
- Does not match the canonical definition of serializability (equivalence to a serial history): does not consider writes

### 5.4 Dependency Issues
The following histories are serializable according to the SQL criteria but is actually cyclic:
- `w1[x], w2[x], w2[y], w1[y]`
- `r1[x], w2[x], r2[y], w1[y]`

However, some system using snapshot isolation as concurrency control consider it correct

![](https://hackmd.io/_uploads/BkE_h3mPi.png =600x)
 
Both read from the last commit, no problem! But there are situations where it is incorrect: dependency between x and y, because the implementation of snapshot isolation allows parallelism of 1 and 2. (Actually uses two-phase lock where this cannot happen)

Locking protocols as implemented by existing engines are stronger than the SQL isolation levels because they consider writes (and recovery)