---
tags: DMS
---

# 03.1 Query Processing 1: Execution Models
[TOC]

## 0. Anatomy of Query Processing
### 0.1 Schematic Diagram of 2-Tier Architecture
#### 1. General Schematic Diagram
![](https://hackmd.io/_uploads/rkaeZjaEi.png =200x)

#### 2. [Schematic Diagram of Oracle Database](https://docs.oracle.com/en/database/oracle/oracle-database/19/cncpt/process-architecture.html#GUID-85D9852E-5BF1-4AC0-9E5A-49F0570DBD7A)

![](https://hackmd.io/_uploads/HkAV-ja4j.png =600x)

The figure shows a system global area (SGA) and background processes using dedicated server connections. 

For each user connection, a client process runs the application. This client process that is different from the dedicated server process that runs the database code. 

Each client process is associated with its own server process, which has its own program global area (PGA).

### 0.2 Schematic Diagram of Query Compiler
#### 1. General Schematic Diagram
![](https://hackmd.io/_uploads/HkVBfs6Ni.png =600x)

#### 2. [Schematic Diagram of IBM DB2](https://www.ibm.com/docs/en/db2/11.5?topic=optimization-sql-xquery-compiler-process)

![](https://hackmd.io/_uploads/rkgsXsaNj.png =600x)

### 0.3 Commercial Systems
All aspects of query optimization are a big part of the difference between commercial database engines and open source (or rather new) engines

## 1. Execution Models
### 1.1 Caching
- Reuse query or intermediate results in the engine
- Reuse query results outside the engine
    - At the application
    - In an intermediate layer
- Reuse parsing or optimization of queries

#### 1. Statement and Result Caching
- **Shared SQL Area (Oracle):** When a query is submitted, it is checked against the Shared SQL Area.
- **Server Result Cache:** When a query executes, check first in the result cache, if it is there, answer from the cache

**Advantages:**
- Work very well when queries are issued repeatedly and data does not change often
- Work like regular caches
    - Possibility of providing hints to use the cache
    - Possibility of pinning results to those caches

#### 2. [Client Result Cache](https://docs.oracle.com/en/database/oracle/oracle-database/12.2/tgdba/tuning-result-cache.html#GUID-4B9DD91E-7F5B-4C8C-80AA-347C2FAEC725)
- Interfaces to access databases are standardized (e.g., JDBC) and often based on libraries
- These libraries include quite a bit of functionality (see later) related to query processing and that might include caching of query results on the client side

![](https://hackmd.io/_uploads/S1VvYFCVo.png =600x)

#### 3. [Intermediate Layer Caching](https://aws.amazon.com/caching/database-caching/)
- In large installations, it might pay off to have an intermediate layer between the database and the application that is used to cache data
- Can be done in synch with the database or just implemented on top
- Useful in, e.g., web applications
- Implemented in e.g. key-value store style: Query as key, Result as value

![](https://hackmd.io/_uploads/HyvRKK0Ej.png =600x)

#### 4. Private Caching vs Shared Caching
![](https://hackmd.io/_uploads/rJYK5YAEo.png =400x)
- **Private caching:** The most basic type of cache is an in-memory store. It's held in the address space of a single process and accessed directly by the code that runs in that process. This type of cache is quick to access. If you have multiple instances of an application that uses this model running concurrently, each application instance has its own independent cache holding its own copy of the data. However, there are consistency issues with this type of strategy!

![](https://hackmd.io/_uploads/r1Uq5KC4i.png =400x)
- **Shared caching:** Shared caching ensures that different application instances see the same view of cached data. It locates the cache in a separate location, which is typically hosted as part of a separate service.

#### 5. Caching Consideration
- Caching can store complete results but also partial results: Cache the static part of the data, query for the dynamic part, Works well for blobs and large data items that do not change often
- Pre-populated caches or on-demand caching

### 1.2 Process/Threads/Pools
Database engines acts as an operating system scheduling, orchestrating, and mediating access to shared resources

#### 1. Notion
- **Client Process (can be a kernel thread):** is the **execution unit** that runs on the client or application side and is used to connect to the database engine
- **Server process (can be a kernel thread):** is the **execution unit** that runs inside the database engine and is used to execute queries on behalf of a client
- **OS Process:** A program execution unit at the level of the operating system with a private address space. It has its own state, its unique address space, and is scheduled and managed by the OS
- **OS Thread:** Part of a multi-threaded process, is a program execution unit that shares its address space and context with other threads from the same process. Scheduled and managed by the kernel

#### 2. [Client and Server Processes (Oracle)](https://docs.oracle.com/en/database/oracle/oracle-database/19/cncpt/process-architecture.html)

![](https://hackmd.io/_uploads/rygtJcREi.png =400x)
![](https://hackmd.io/_uploads/B17yg9CEo.png =600x)

- **Client-Server Connection:** ensures latency (SLA)! where throughput is designed upon thereafter
- **Multi-programming Label:** how many processes are running in parallel (per core), usul. very small (~2)

#### 3. [Client and Server Processes (Postgres)](https://www.slideshare.net/oddbjorn/Get-to-know-PostgreSQL)

#### 4. Approach 1: Using OS Processes (Process per Worker)
Each session is managed by a separate OS server process

**Advantages:**
- Takes advantage of isolation and security properties of processes
- Easier to implement

**Disadvantages:**
- Limited scalability
- Context switching of processes is slow as processes maintain a lot of state
- Many shared data structures across processes (buffer cache, lock table, common memory pools) are less isolated than in an OS context
- Implementing parallel query processing is more involved

#### 5. Approach 2: Using Threads (Thread per Worker)
**Advantages:**
- Threads are lighter in terms of state and management, and scale better
- Shared state simplifies access to common data structures
- Shared memory among threads facilitates parallel query processing
- Today, modern systems based on threads

**Disadvantages:**
- More involved implementation as threads must be managed
- Lacks the protections and isolation of processes (a thread can affect what others do)

#### 6. Approach 3: Process or Thread Pools
Like the previous approach but a client request is managed by several server processes (processes or threads)
- One entity deal with connections and scheduling
- Actual queries are passed on to the pool, where a process or a thread is used to execute the query and return the results back to the controlling entity

**Advantages:**
- Makes it easier to implement parallel query processing
- The pool can be resized
- Scales better

#### 7. Memory Structures
- System Global Area for shared resources
- Database Buffer Cache for I/O
- Redo Log Buffer for recovery
- Large Memory pool: optional additional memory for some procedures

#### 8. Program Global Area in a Server Process (Worker)
![](https://hackmd.io/_uploads/HJ6VocR4s.png =300x)
![](https://hackmd.io/_uploads/SkvSiqR4j.png =400x)

Organized by:
- Query processing (sort, hash table, bitmap merge areas)
- Session information
- Parameters (private area)
- Cursor status (private area)

#### 9. Cursor
A cursor is a pointer to a table, indicating what is the next tuple to be delivered. 

Cursors can be declared, opened, closed, accessed, etc.

Databases use cursors, internally and also towards clients, as a way to return results

### 1.3 Execution Models
#### 1. Query Tree
![](https://hackmd.io/_uploads/HyhmT9RNo.png =600x)

Execution is modelled as a tree of operators
- At the leaves we have tables
- At the root we have the query results
- Typically, each operator has at most two inputs from lower layers (join)

A table and a query are the same (the query is a representation of the table)
- Any subtree of the query can be “materialized” as a table and used as input for the higher parts of the tree
- Queries can create tables that are then used as inputs for other queries (views)

#### 2. Basic Executions
Each node in the tree (operator) functions independently: 
- It reads its input
- Processes it
- Produces an output

Operators can read their input tuple and output their results tuple at a time or as a whole

Some operators might be blocking (cannot issue any result until all operations are completed), others can read input tuples, process them, and issue result tuples in a pipeline fashion.

#### 3. Single Machine Execution Model 1: Iterator Model
Also: Volcano or pipeline execution model

Tuples traverse the tree from leaves to the root. Operators iterate over those tuples to process them. 
- data flows bottom up in a plan (i.e. operator tree)
- control flows top down in a plan

```sql
SELECT Students.Name, Students.Address
FROM Students, Attends
WHERE Attends.Name = Students.Name AND Attends.Class = “Data Management”
```

![](https://hackmd.io/_uploads/BJafMmFri.png =600x)

**Notes:**
- this is a Nested Loop Join
- operators are instantiated according to data types

**Advantages:**
- generic interface for all operators: great information hiding
- easy to implement iterators (clear what to do in any phase)
- Supports buffer management strategies
- no overheads in terms of main memory
- supports pipelining: great if only subset of results consumed
- supports parallelism and distribution: add special iterators

**Disadvantages:**
- high overhead: too many function calls and they are expensive! e.g. context switch
- poor cache locality: cache misses both in data and instructions: cache pollution
- no room for compiler optimizations

#### 4. Typical Dataflow operators
- **Union**: read both sides, issue all tuples (same schema)
- **Union without duplicates**: Union + Remove duplicates (grab one tuple, check against all others, issue if no matches)
- **Select:**
    ```
    Read tuple
    While tuple doesn’t meet predicate
        Read tuple
    Return tuple
    ```
- **Projection:**
    ```
    Read tuple
    While more tuples
        Output specified attributes
        Read tuple
    ```
- **Join**: Trivial nested loop join
- **Join with an index on inner relation:** 
    ```
    For all tuples in R
        fetch matching tuple in S <= another operator
        output joined tuples
    ```

#### 5. Single Machine Execution Model 2: Materialization Model
Operators produce all of their output in one go and make it available in some buffer, the next operator uses that buffer as input to produce its own buffer

```sql
SELECT Students.Name, Students.Address
FROM Students, Attends
WHERE Attends.Name = Students.Name AND Attends.Class = “Data Management”
```

![](https://hackmd.io/_uploads/rk7HMmKHj.png =600x)

**Notes:**
- customized operators based on compression
- buffer can be smaller than table
- bottom-up plan where the operators first complete the operation on the whole table before emitting it up to the higher nodes.

**Advantages:**
- remove function calls
- no instruction cache misses
- read sequentially on the cache
- it works well in OLTP (Online Transaction Processing) where queries and transactions do not process a lot of data and, thus, can use small buffers to pass data around
    - Potentially more efficient for short queries because there are less function calls and less execution overhead
- Room for compiler optimizations

**Disadvantages:**
- not suitable for analytics as the data being passed from operator to operator can be very large
- only for column store
- complex operators
- complex interface
- difficult to pipeline as subsequent processing steps receive full tables
- large memory usage and very bad scaling as materialization occurs at every step
- difficult buffer management.
- full materialization, very bad memory utilization

#### 6. Single Machine Execution Model 3: Vectorization Model
Also: Batch Model

Operators work on sets of tuples rather than single tuples of the whole input, they read sets of input tuples and produce sets of result tuples

A combination of iterator and materialization model:
- Iterates over data using `Next`
- Every next call returns a set of tuples instead of a full buffer or a single tuple

**Advantages:**
- Reduces the number of calls over iterator model
- Makes implementation of certain operators more efficient (Exploits SIMD/AVX in CPUs and column storage)
- Works best for analytical queries, widely used in data warehouses (OLAP)
- Scales well as the operators are simple and can be easily parallelized.
- Easy to pipeline.
- The vectorization model preserves the simple interface of the iterator model which is based around the next() function.
- The vectorization model preserves the simple interface of the iterator model and thus it permits simple operators as well.

**Disadvantages:** Same downsides as the iterator model