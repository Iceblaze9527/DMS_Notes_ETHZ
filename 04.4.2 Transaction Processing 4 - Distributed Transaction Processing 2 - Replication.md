---
tags: DMS
---

# 04.4.2 Transaction Processing 4: Distributed Transaction Processing 2 - Replication
[TOC]

## 4.3.1 Database Replication
### 1. Why Replication
![](https://hackmd.io/_uploads/r1F7MyTOi.png =600x)

### 2. How to replicate data?
There are two basic parameters to select when designing a replication strategy: where and when.

#### Depending on when the updates are propagated:
- Synchronous (eager)
- Asynchronous (lazy)

#### Depending on where the updates can take place:
- Primary Copy (master)
- Update Everywhere (group)

## 4.3.2 Replication Strategies
### 1. Sync Replication
Synchronous replication propagates any changes to the data immediately to all existing copies. 

Typically done in the context of transactions: the changes are propagated within the scope of the transaction making the changes. 

The ACID properties apply to all copy updates.

![](https://i.imgur.com/oq60Xxw.png =600x)

#### Procedure
1. A SITE WANTS TO UPDATE THE PRICE
2. IT FIRST CONSULTS WITH EVERYBODY ELSE
3. AN AGREEMENT IS REACHED
4. THE PRICE IS UPDATED AND PROCESSING CONTINUES

### 2. Async Replication
Asynchronous replication first executes the updating transaction on the local copy. Then the changes are propagated to all other copies. 

While the propagation takes place, the copies are inconsistent (they have different values).

The time the copies are inconsistent is an adjustable parameter which is application dependent. You need to write an app that does not trust what the system does

![](https://i.imgur.com/A6YB6Xc.png =600x)

#### Procedure
1. A SITE WANTS TO UPDATE THE PRICE
2. THEN IT UPDATES THE PRICE LOCALLY AND CONTINUES PROCESSING (DATA IS NOT CONSISTENT!)
3. THE UPDATE IS **EVENTUALLY** PROPAGATED TO ALL SITES [(PUSH, PULL MODELS)](https://medium.com/@_JeffPoole/thoughts-on-push-vs-pull-architectures-666f1eab20c2)

### 3. Update Everywhere
With an update everywhere approach, changes can be initiated at any of the copies. That is, any of the sites which owns a copy can update the value of the data item.

![](https://i.imgur.com/4BA8lbA.png =800x)

#### Procedure
ALL SITES ARE ALLOWED TO UPDATE THEIR COPY

Problem: potential deadlock

### 4. Primary Copy
With a primary copy approach, there is only one copy which can be updated (the master), all others (secondary copies) are updated reflecting the changes to the master.

![](https://i.imgur.com/of1spBD.png =800x)

#### Procedure
ONLY ONE SITE IS ALLOWED TO DO UPDATES, THE OTHER ARE READ ONLY COPIES

### 5. Summary
There is a trade-off between correctness (data consistency) and performance (throughput and response time).

#### Forms of Replication
![](https://i.imgur.com/OVgL2e2.png =600x)

#### Four Categories
![](https://i.imgur.com/lZKGIbX.png =600x)

#### Ideal vs Practical
![](https://hackmd.io/_uploads/B1B2rJ6Oo.png =500x)![](https://hackmd.io/_uploads/S1UaBkauo.png =500x)

## 4.3.3 Implementing Replication
### 1. Managing Replication
#### Isolation and 2PL
- Isolation is guaranteed by a concurrency control protocol.
- In commercial databases, this is usually 2 Phase Locking (2PL)

#### Atomicity and 2PC
- When a transaction executes at various sites, it must execute an atomic commitment protocol, i.e., it must commit at all sites or at none of them.
- Commercial systems use 2 Phase Commit

#### Transaction Manager
![](https://hackmd.io/_uploads/r1DowhT_j.png =300x)

The transaction manager takes care of isolation and atomicity.

#### Serialization Issues
![](https://hackmd.io/_uploads/HJwD_3aOi.png =300x)

When the data is replicated, we need to make sure the serialization orders are the same at all sites, otherwise the copies would be inconsistent.

#### Solution: Replication Protocol
![](https://hackmd.io/_uploads/B1XEKnaOs.png =300x)

The replication protocols depend on the replication strategy.

#### Cost of Replication
Assume a `N` node replicated system where a fraction `s` of the data is replicated and `w` represents the fraction of updates made (`ws` = replication factor)

Overall computing power of the system:$$\frac{N}{1+w \cdot s \cdot(N-1)}$$

![](https://hackmd.io/_uploads/B1QR_Tp_i.png =300x)

### 2. Implementation - Synchronous, Update Everywhere
![](https://hackmd.io/_uploads/S1QAmRT_s.png =300x)
- Data consistency is guaranteed. 
- Performance may be affected. 
- High fault tolerance.

#### Read-one-write-all
- Each sites uses 2 Phase Locking.
- Read operations are performed locally.
- Write operations are performed at all sites (using a distributed locking protocol).

This protocol guarantees that every site will behave as if there were only one database. The execution is serializable (correct) and all reads access the latest version (2PL locking across the machines).

#### Write All Available Copies
- READ = read any copy, if time-out, read another copy.
- WRITE = send Write(x) to all copies. If one site rejects the operation, then abort. Otherwise, all sites not responding are “missing writes”.
- VALIDATION = To commit a transaction
    - Check that all sites in “missing writes” are still down. If not, then abort the transaction.
    - Check that all sites that were available are still available. If some do not respond, then abort.

#### Quorum Protocol
Quorums are sets of sites formed in such a way so as to be able to determine that it will have a non-empty intersection with other quorums:
- Simple majorities (site quorums).
- Weighted majorities (quorum consensus).
- Logical structures (tree, matrix, projective planes quorums).

Let `RT` and `WT` be read and write thresholds, respectively, such that:
- `2 WT > N`
- `RT + WT > N`
- usually, `RT=WT=N/2+1`

A read quorum is a set of copies such that their total weight is greater or equal to `RT`.

A write quorum is a set of copies such that their total weight is greater or equal to `WT`.

Weighted Quorums:
- Each copy has a weight assigned to it.
- The total weight of all copies is `N`.

#### Issues: Response Time
![](https://hackmd.io/_uploads/B1HXVApdi.png =600x)

Snapshot isolation: no locks, performance advantages
- SI does not wait for remote writes
- communication cost reduced due to the usage of shadow pages
- it is more advantageous especially when you use asynchronous: the secondary copy is equivalent to a snapshot on a remote machine (if the network is fast enough you will have the identical semantics)

#### Issues: Deadlocks
Approximated deadlock rate: $$
\frac{\text { TPS }^2 \cdot \text { Action_Time } \cdot \text { Actions }^5 \cdot \mathbf{N}^3}{4 \cdot \text { DB_Size }^2}$$ if the database size remains constant $$
\frac{\text { TPS }^2 \cdot \text { Action_Time } \cdot \text { Actions }^5 \cdot \mathbf{N}}{4 \cdot \text { DB_Size}^2}$$

The system will not scale because of deadlocks (as the number of nodes increases, the probability of getting into a deadlock gets too high)

#### Common Solution Today
![](https://hackmd.io/_uploads/B1wCgyA_o.png =300x)

### 3. Implementation - Synchronous, Primary Copy
#### Advantages:
- Updates do not need to be coordinated
- No inconsistencies, no deadlocks.
- Less scalability problems. 
- Data consistency is guaranteed. 
- Fault tolerant.

#### Disadvantages:
- Longest response time
- **Useful for mixed workloads**: real-time monitoring
- Local copies are good for analytics
- Common architecture in the cloud

### 4. Implementation - Asynchronous, Primary Copy
![](https://hackmd.io/_uploads/SyNLFkAOj.png =400x)

- Update transactions are executed at the primary copy site
- Read transactions are executed locally
- After the transaction is executed, the changes are propagated to all other sites

#### Advantages:
- No coordination necessary
- Short response times (transaction is local)
- Facilitate for mixed OLTP/OLAP
- Performance is good (almost same as if no replication). 

#### Disadvantages:
- Local copies are not up to date (a local read will not always include the updates made at the local copy)
- Inconsistencies (different sites have different values of the same data item). It depends on how you propagate the changes
- Fault tolerance is limited.

### 5. Implementation - Asynchronous, Update Everywhere
#### Reconcilation
![](https://hackmd.io/_uploads/SJzN6y0Oo.png =300x)

Probability of needing reconciliation:$$\frac{\text {TPS}^2 \cdot \text {Action_Time} \cdot \text {Actions}^3 \cdot \mathbf{N}^3}{2 \cdot \text {DB_Size }}$$

Such problems can be solved using pre-arranged patterns:
- Latest update win (newer updates preferred over old ones)
- Site priority (preference to updates from headquarters)
- Largest value (the larger transaction is preferred)

or using ad-hoc decision making procedures:
- identify the changes and try to combine them
- analyze the transactions and eliminate the non-important ones
- implement your own priority schemas

#### Advantages:
- No centralized coordination
- Shortest response times
- Performance is excellent (same as no replication).
- High fault tolerance.

#### Disadvantages:
- Inconsistencies
- Reconciliation is a tough problem (to be solved almost manually).

## 4.3.4 Example: Key Value Stores
### 1. KVS Architecture
#### Schema
- Key + BLOB (or pointer to blob)
- Index on key (hashing)

#### Deployment
- Horizontal Partitioning
- Replication of Partitions

#### Replication strategy
- Quorums (simple majority)
- Asynchronous replication across all copies (eventual consistency)

### 2. Advantages and Disadvantages
#### Advantages
- Very fast lookups (hashing)
- Easy to scale to many machines (simply add more copies/machines): 
    - Excellent match for the cloud’s elasticity
    - Can be implemented in main memory of machines (faster access)

#### Disadvantages
- No easy support for queries beyond point queries as data is treated as a BLOB
- Depending on implementation, data can appear as being inconsistent