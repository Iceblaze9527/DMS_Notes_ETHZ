---
tags: DMS
---

# 05.2 Distributed Transaction Processing 2: Replication
[TOC]

## 1. Database Replication
### 1.1 Why Replication
![](https://hackmd.io/_uploads/r1F7MyTOi.png =600x)

### 1.2 How to replicate data?
There are two basic parameters to select when designing a replication strategy: where and when.

#### Depending on when the updates are propagated:
- Synchronous (eager)
- Asynchronous (lazy)

#### Depending on where the updates can take place:
- Primary Copy (master)
- Update Everywhere (group)

## 2. Replication Strategies
### 2.1 Sync Replication
Synchronous replication propagates any changes to the data immediately to all existing copies. 

Typically done in the context of transactions: the changes are propagated within the scope of the transaction making the changes. 

The ACID properties apply to all copy updates.

![](https://i.imgur.com/oq60Xxw.png =600x)

#### Procedure
1. A SITE WANTS TO UPDATE THE PRICE
2. IT FIRST CONSULTS WITH EVERYBODY ELSE
3. AN AGREEMENT IS REACHED
4. THE PRICE IS UPDATED AND PROCESSING CONTINUES

### 2.2 Async Replication
Asynchronous replication first executes the updating transaction on the local copy. Then the changes are propagated to all other copies. 

While the propagation takes place, the copies are inconsistent (they have different values).

The time the copies are inconsistent is an adjustable parameter which is application dependent. You need to write an app that does not trust what the system does

![](https://i.imgur.com/A6YB6Xc.png =600x)

#### Procedure
1. A SITE WANTS TO UPDATE THE PRICE
2. THEN IT UPDATES THE PRICE LOCALLY AND CONTINUES PROCESSING (DATA IS NOT CONSISTENT!)
3. THE UPDATE IS **EVENTUALLY** PROPAGATED TO ALL SITES [(PUSH, PULL MODELS)](https://medium.com/@_JeffPoole/thoughts-on-push-vs-pull-architectures-666f1eab20c2)

### 2.3 Update Everywhere
With an update everywhere approach, changes can be initiated at any of the copies. That is, any of the sites which owns a copy can update the value of the data item.

![](https://i.imgur.com/4BA8lbA.png =800x)

#### Procedure
ALL SITES ARE ALLOWED TO UPDATE THEIR COPY

Problem: potential deadlock

### 2.4 Primary Copy
With a primary copy approach, there is only one copy which can be updated (the master), all others (secondary copies) are updated reflecting the changes to the master.

![](https://i.imgur.com/of1spBD.png =800x)

#### Procedure
ONLY ONE SITE IS ALLOWED TO DO UPDATES, THE OTHER ARE READ ONLY COPIES

### 2.5 Summary
There is a trade-off between correctness (data consistency) and performance (throughput and response time).

![](https://i.imgur.com/OVgL2e2.png =600x)

### 2.6 Put Together
#### Comparison
|                     | Sync Primary Copy | Sync/Update Everywhere | Async/Primary Copy | Async/Update Everywhere |
| ------------------- | ----------------- | ---------------------- | ------------------ | ----------------------- |
| **Coordination**    | No                | Yes                    | No                 | No centralized          |
| **Scalability**     | High              | Low                    | High               | High                    |
| **Consistency**     | Consistent        | Consistent             | Inconsistent       | Inconsistent            |
| **Fault Tolerance** | High              | High                   | Low                | High                    |
| **Response Time**   | Longest           | Long                   | Short              | Shortest                |
| **Performance**     | Lowest            | Low                    | High               | Highest                 |

#### Ideal vs Practical
![](https://hackmd.io/_uploads/B1B2rJ6Oo.png =500x)![](https://hackmd.io/_uploads/S1UaBkauo.png =500x)

## 3. Implementing Replication
### 3.1 Managing Replication
#### Transaction Manager
![](https://hackmd.io/_uploads/r1DowhT_j.png =300x)

The transaction manager takes care of isolation and atomicity.

- Isolation Guarantee: 2PL
- Atomicity uarantee: 2PC

#### Serialization Issues
![](https://hackmd.io/_uploads/HJwD_3aOi.png =300x)

When the data is replicated, we need to make sure the serialization orders are the same at all sites, otherwise the copies would be inconsistent.

#### Solution: Replication Protocol
![](https://hackmd.io/_uploads/B1XEKnaOs.png =300x)

The replication protocols depend on the replication strategy.

#### Cost of Replication
Assume a `N` node replicated system where a fraction `s` of the data is replicated and `w` represents the fraction of updates made (`ws` = replication factor)

Overall computing power of the system:$$\frac{N}{1+w \cdot s \cdot(N-1)}$$

![](https://hackmd.io/_uploads/B1QR_Tp_i.png =300x)

### 3.2 Implementation - Synchronous, Update Everywhere
![](https://hackmd.io/_uploads/S1QAmRT_s.png =300x)

#### Basic Strategy: Read-one-write-all
Assume all sites contain the same data.
- Each sites uses 2 Phase Locking.
- Read operations are performed locally.
- Write operations are performed at all sites (using a distributed locking protocol).

#### Site Failures: Write All Available Copies
Assume, for the moment, that there are no communication failures. Instead of writing to all copies, we could

- **READ =** read any copy, if time-out, read another copy.
- **WRITE =** send Write(x) to all copies. If one site rejects the operation, then abort. Otherwise, all sites not responding are “missing writes”.
- **VALIDATION =** To commit a transaction
    - Check that all sites in “missing writes” are still down. If not, then abort the transaction.
    - Check that all sites that were available are still available. If some do not respond, then abort.

#### Communication Failures: Quorum Protocol
Quorums are sets of sites formed in such a way so as to be able to determine that it will have a non-empty intersection with other quorums:
- Simple majorities (site quorums).
- Weighted majorities (quorum consensus).
- Logical structures (tree, matrix, projective planes quorums).

#### Example: Weighted Quorums
Each copy has:
- a weight assigned to it. The total weight of all copies is `N`.
- a version number.

Let `RT` and `WT` be read and write thresholds, respectively, such that:
- `2 WT > N`
- `RT + WT > N`
- usually, `RT=WT=N/2+1`

Quorums:
- **read quorum:** a set of copies such that their total weight is greater or equal to `RT`.
- **write quorum:** a set of copies such that their total weight is greater or equal to `WT`.

Read and Write:
- **READ =** contact sites until a read quorum is formed. then read the copy with the highest version number.
- **WRITE =** contact sites until a write quorum is formed. Get the version number of the copy with the highest version number (k). Write to all sites in the quorum adding the new version number (k+1).

Recovery is for free! but reading is no longer local and it is not possible to change the system dynamically.

#### Issues: Response Time
![](https://hackmd.io/_uploads/B1HXVApdi.png =600x)

The way replication takes place (one operation at a time), increases the response time and, thereby, the conflict profile of the transaction. The message overhead is too high (even if broadcast facilities are available).

#### Issues: Deadlocks
Approximated deadlock rate: $$
\frac{\text { TPS }^2 \cdot \text { Action_Time } \cdot \text { Actions }^5 \cdot \mathbf{N}^3}{4 \cdot \text { DB_Size }^2}$$ if the database size remains constant $$
\frac{\text { TPS }^2 \cdot \text { Action_Time } \cdot \text { Actions }^5 \cdot \mathbf{N}}{4 \cdot \text { DB_Size}^2}$$

The system will not scale because of deadlocks (as the number of nodes increases, the probability of getting into a deadlock gets too high)

#### Solution Today: Pre-ordering Mechanism
![](https://hackmd.io/_uploads/B1wCgyA_o.png =300x)

### 3.3 Implementation - Asynchronous, Primary Copy
![](https://hackmd.io/_uploads/SyNLFkAOj.png =400x)

- Update transactions are executed at the primary copy site
- Read transactions are executed locally
- After the transaction is executed, the changes are propagated to all other sites
- Locally, the primary copy site uses 2 Phase Locking
- In this scenario, there is no atomic commitment problem (the other sites are not updated until later)

### 3.4 Implementation - Asynchronous, Update Everywhere
![](https://hackmd.io/_uploads/SJzN6y0Oo.png =300x)

- All transactions are executed locally
- After the transaction is executed, the changes are propagated to all other sites
- Locally, a site uses 2 Phase Locking
- In this scenario, there is no atomic commitment problem (the other sites are not updated until later)

#### Reconcilation
Probability of needing reconciliation:$$\frac{\text {TPS}^2 \cdot \text {Action_Time} \cdot \text {Actions}^3 \cdot \mathbf{N}^3}{2 \cdot \text {DB_Size }}$$

Such problems can be solved using pre-arranged patterns:
- Latest update win (newer updates preferred over old ones)
- Site priority (preference to updates from headquarters)
- Largest value (the larger transaction is preferred)

or using ad-hoc decision making procedures:
- identify the changes and try to combine them
- analyze the transactions and eliminate the non-important ones
- implement your own priority schemas

### 3.5 Snapshot Isolation
No locks, performance advantages
- SI does not wait for remote writes
- communication cost reduced due to the usage of shadow pages
- it is more advantageous especially when you use asynchronous: the secondary copy is equivalent to a snapshot on a remote machine (if the network is fast enough you will have the identical semantics)

## 4. Example: Key Value Stores
### 4.1 KVS Architecture
#### No Schema
- Key + BLOB (or pointer to blob)
- Index on key (hashing)

#### No SQL
- Get and Set as the only operations

#### No ACID
- Eventual consistency
- Potentially no transactions

#### Deployment
- Horizontal Partitioning
- Replication of Partitions

#### Replication strategy
- Quorums (simple majority)
- Asynchronous replication across all copies (eventual consistency)

### 4.2 Advantages and Disadvantages
#### Advantages
- Very fast lookups (hashing)
- Easy to scale to many machines (simply add more copies/machines): 
    - Excellent match for the cloud’s elasticity
    - Can be implemented in main memory of machines (faster access)
- Works well as cache or specialized system

#### Disadvantages
- No easy support for queries beyond point queries as data is treated as a BLOB: Range queries require to read all copies, Joins out of the question
- Depending on implementation, data can appear as being inconsistent
- Pushes complexity and responsibility to the application. That complexity will affect the development of applications
- Some operations are very costly to implement
- Not a replacement for a full blown database