---
tags: DMS
---

# 04.3 Transaction Processing 3: Recovery
[TOC]

## 3.0 Failures
In this section we will focus on system failures

### 1. Transaction Failure
#### Types
- transaction aborts
- rollbacks
- client fails in the middle of executing a transaction
- transaction times out

#### Solutions
- Typically done using undo logs or undo records (see last section)
- Transactions must create an undo record every time they modify something
- The undo record is used to remove the changes made by the active transactions

### 2. System Failure
#### Types
- machine shuts down
- machine fails
- OS bails out

#### Solutions
- Typically done using redo and undo logs as well as by running a recovery procedure
- Undo the changes of active transactions at the time of failure, redo the changes of committed transactions
- Clean up the data in permanent storage

### 3. Media Failure
#### Types
- disk fails
- permanent storage has errors, etc.

#### Solutions
- replication
- separating data files from log files

### 4. Requirements for the Recovery Procedure
- Recover database state up to the changes made by all committed transactions as of the time of failure.
- Operate only with the data on permanent storage
- Idempotent: Be correct even when successive failures occur in the middle of the recovery procedure

## 3.1 Logging
### 1. Notations
- **Before Image:** The value that existed in the database before a transaction modifies an item
- **After Image:** The value that exists in the database after a transaction modifies an item
- **Log Record:** A record that registers what the transaction has done (a before image, and after image, transaction id, SCN, LSN, etc.)
    - In a database engine, both the data and the log are persistent; recovery procedures will combine both depending on the design
- We will assume **serializable and strict execution:**
    - A transaction can be undone by restoring its before images
    - A transaction can be redone by applying its after images

:::info
**Is strict execution is required for correct recovery?**

Execution that is recoverable is the weakest requirement on execution that allows for correct recovery. However, strict execution may be preferred to simplify the recovery procedure 
- (A) It avoids cascading aborts (ACA) so to undo writes of a transaction only before images from that transaction are necessary.
- (B) Strict implies that committed writes will execute in the same order as their corresponding transactions commit, therefore the last committed value of an item will be written by the last committed transaction that wrote that item.
:::

### 2. Assumptions for Logs
- there is a log record for each modification made by a transaction
- use SCN or LSN to order and reflect the logical sequence of events in the databases
- **physical logging:** the log entries contain the actual data modified by the transaction
- **persistency:** the log is kept in stable storage
- **flush operations:** force that something is written to permanent storage

### 3. Durability
![](https://hackmd.io/_uploads/H1n2rP7us.png =600x)

#### REQUIRES UNDO
UNDO the updates from uncommited transactions that might be in persistent storage

To undo changes: we need the before image (UNDO LOG)

#### REQUIRES REDO
REDO updates from commited transactions not persistent at commit time

To redo changes: we need the after image (REDO LOG)

## 3.2 Recovery Procedures
:::info
For the questions regarding execution, consider the database persistent state with 5 items (X1-X5) with the following values:

X1:10, X2:20, X3:8, X4:16, X5:32 

This is the database state at the beginning of the execution of the recovery procedure. (might not be correct!)

And persistent log where each entry contains Log Sequence Number, Transaction ID, Item ID, Before Image, and After Image

```
#LSN, TXid, item, BI, AI
1001, T1, X1, 2, 10
1002, T1, X2, 4, 20
1003, T2, X3, 8, 30
1004, T2, X3, 8, 33
1005, T1, X4, 16, 40
1006, T2, COMMIT
1007, T1, X3, 33, 36
1008, T3, X5, 32, 50
1009, T3, COMMIT
```
:::


### 1. Buffer Cache Policies
The recovery manager implements the recovery procedure

#### Steal Policy
**STEAL:** an uncommitted transaction is allowed to overwrite in persistent storage the changes of a committed transaction
- This happens by pushing a dirty block to storage before the transaction commits
- Will require to be able to **undo** this transaction

#### Force Policy
**FORCE:** all changes made by a transaction must be in persistent storage before the transaction commits
- Requires to flush all blocks with updates form the transaction
- If not in place, it will require to be able to redo the transaction

### 2. UNDO/REDO
#### Transaction Operations
- **READ:** Just read the value from the block on the buffer cache
- **WRITE:** 
    - Create log entry (before image, after image) and append it to the persistent log
    - Write after image to block on the buffer cache
- **COMMIT:** Write a persistent log entry indicating the transaction has committed
- **ABORT:** For all updates, restore the before image using the log entry

#### Recovery Procedure
```python!
UNDONE, REDONE = [], []

for entry in reversed(LOG):
    T, x = entry.transaction, entry.item
    BI, AI = entry.before_image, entry.after_image

    if not (x in UNDONE or x in REDONE):
            if T in COMMITED:
                apply_image(x,AI)
                REDONE.append(x)
            else:# T in ABORTED
                apply_image(x,BI)
                UNDONE.append(x)
    
    if set(zip(*UNDONE)[0]) | set(zip(*REDONE)[0]) == set(DATA.keys()):
        break # Procedure terminates when all items are in either the UNDONE or REDONE list

>>> COMMITED
[(T3,1009),(T2,1006)]
>>> REDONE
[(X5,1008)]
>>> UNDONE
[(X3,1007),(X4,1005),(X2,1002),(X1,1001)]
>>> DATA
{X1:2, X2:4, X3:33, X4:16, X5:50}
```

#### Alternative Way
```!
For every item in the database:
    Find the last committed transaction that modified the item and REDO the modification
    If no committed transaction modified the item, find the first aborted transaction than modified the item and UNDO the modification
    If no transaction has touched the item, its value is correct (we assume we start from a consistent state)
```

In practice, not done like this because there are many more items than log entries, easier to process the log sequentially from end to the beginning.

#### Advantages
- The procedure ignores the data stored on disk as it could correspond to uncommitted transactions (hence the need for UNDO), it only takes it as starting point for recovery
- The only forced I/O are log records
- Buffer Cache manager has a lot of freedom:
    - No need to flush dirty pages if there is no need to reuse the space
    - I/O on data is minimized and only triggered for block replacement policies
    - Allows to write dirty data (written by uncommitted transactions) to disk, which simplifies buffer management
- Recovery is more complicated and takes more time but normal operations are only minimally affected
    - Queries are not affected since there is no forced I/O of data
    - Transactions are affected because the need to write every operation to the log

### 3. UNDO/NO-REDO
#### Transaction Operations
- **READ:** Just read the value from the block in the buffer cache
- **WRITE:**
    - Create log entry ==(before image)== and append it to the persistent log
    - Write after image to block on the buffer cache
- **COMMIT:**
    - ==Flush all dirty values modified by the transaction if still in the cache==
    - Write a persistent log entry indicating the transaction has committed
- **ABORT:** For all updates, restore the before image using the log entry

#### Recovery Procedure
```python!
UNDONE = []

for entry in reversed(LOG):
    T, x = entry.transaction, entry.item
    BI = entry.before_image

    if (not x in UNDONE) and (not T in COMMITED):
        apply_image(x,BI)
        UNDONE.append(x)
    
    if set(zip(*UNDONE)[0]) == set(DATA.keys()):
        break

>>> COMMITED
[(T3,1009),(T2,1006)]
>>> UNDONE
[(X3,1007),(X4,1005),(X2,1002),(X1,1001)]
>>> DATA
{X1:2, X2:4, X3:33, X4:16, X5:32}
```

#### Alternative Way
```!
For every item in the database
    If no aborted transaction has touched it, then it is correct
    Otherwise, find the last aborted transaction that touched the item and UNDO it
```

It works because we are assuming strict execution:
- There can only be one aborted transaction that modified the correct value at the time of failure (cannot overwrite uncommitted items)
- It is enough to undo that transaction and we have the last committed value

#### Advantages
- The procedure relies on the fact that all committed values are in persistent storage and, therefore, they have not been lost
- Forced I/O on all dirty blocks touched by a transaction when it commits
- Log records no longer need to include after images, making the log records smaller
- Recovery procedure is shorter: only involves undoing aborted transactions (theoretically, we would not even need the log entries of committed transactions)

#### Disadvantage
The trade-off induced by no-REDO does not pay off in practice:
- We still need to write to the log with every update
- No-REDO requires smaller log records But it forces I/O on data blocks which are often much larger!
- Flushing the buffer cache interferes with its operation (e.g., queries)

### 4. NO-UNDO/REDO
#### Transaction Operations
- **READ:**
    - If the transaction did not write the item before, read the value from the block in the buffer cache
    - ==If the transaction has written the item before, read the value from some temporary buffer (e.g., shadow page) (not buffer cache!)==
- **WRITE:**
    - Create the log entry ==(after image)== and append it to the persistent log
    - ==Write the after image to the temporary buffer== 
- **COMMIT:**
    - ==Apply all updates in the temporary buffer to the actual data blocks==
    - Write a persistent log entry indicating the transaction has committed
- **ABORT:** Discard the temporary buffer

#### Recovery Procedure
```python!
REDONE = []

for entry in reversed(LOG):
    T, x = entry.transaction, entry.item
    AI = entry.after_image

    if (not x in REDONE) and (T in COMMITED):
        apply_image(x,AI)
        REDONE.append(x)
    
    if set(zip(*REDONE)[0]) == set(DATA.keys()):
        break

>>> COMMITED
[(T3,1009),(T2,1006)]
>>> REDONE
[(X5,1008),(X3,1004)]
>>> DATA
{X1:10, X2:20, X3:33, X4:16, X5:50}
```

#### Alternative Way
```!
For every item in the database
    Find the last committed transaction that touched it and REDO it
```

The step is needed because we are not flushing data blocks at commit and it could be that the changes of a committed transaction are not yet in persistent storage, hence the need to redo those changes upon recovery

#### Advantages
- The procedure relies on the fact that there are never dirty blocks in the buffer cache. All data there is committed and is the last committed version
- Forced I/O only on the log records
- Log records no longer need to include before images, making the log records smaller
- Recovery procedure is shorter: only involves redoing the last committed transaction that touched an item (theoretically, we do not need log entries for aborted transactions)

### 5. NO-UNDO/NO-REDO
#### Data Structure
![](https://hackmd.io/_uploads/HkpSoY7Oo.pn =600x)

#### Transaction Operations
- **READ:**
    - If the value has not been written before by the transaction, using the current directory to find the latest committed copy
    - If the value has been written before by the transaction, use the shadow directory of that transaction to find the updated copy
- **WRITE:** Write to a buffer and add a pointer in the shadow directory for the transactions
- **COMMIT:** 
    - Create a full directory by merging the current one and the shadow directory of the transaction
    - Swap the pointer indicating the latest committed directory
- **ABORT:** Discard the buffer and the shadow directory

#### Notes
- Not used in practice although some of the ideas can be partially applied
- Access to storage requires an indirection through the directory that indicates which one is the latest version. This is too expensive
- It requires garbage collection of all the uncommitted values, shadow directories, etc.
- It moves data all the time, creating problems with the block representation in, e.g., clustered indexes or hash clustered tables

## 3.3 Implementation of Recovery
### 1. Log Blocks vs Data Blocks
- Data is stored in blocks (tendency is towards large blocks)
- Log records are stored in blocks (tendency is towards smaller blocks)
- But they are not blocks of the same size: each log record uses one log block
- Many systems use a log block size of 512 bytes: This is the size of a physical sector on disks

### 2. LSN and SCN
Systems use a number of timestamps to identify the moment transactions start and also to order events in the system:
- **LSN(Log Sequence Number):** LSN are used in the log to order transactions and decide what goes before or after. Also used to indicate log files.
- **SCN(System Change Number):**
    - SCN are used in snapshot isolation to identify correct snapshots
    - SCN are also attached to data to indicate the version of the data (which transaction modified the data last)

### 3. Managing the Log (Oracle Example)
#### In-memory Log: Redo Log 
![](https://hackmd.io/_uploads/HJp_atQ_o.png =400x)

Circular Buffer in Memory
- As transactions modify data, redo records are created in memory and placed in the redo log buffer
- When a commit occurs, the redo records are flushed to a file in storage

#### In-storage Log
![](https://hackmd.io/_uploads/SyNO0tQ_i.png =300x)

- The log writer only writes to a single redo log file at a time
- When a file is full and needs to be archived, the LSN is increased and the system switches to a new redo log file
- That way, archival does not interfere with normal operations as the system always has a redo log file where it can write

### 4. Bottleneck: Group Commit
Instead of flushing the log buffer for every transaction, systems often commit transactions in groups or batches:
- Slight delay in committing but less I/O since all the log entries are written in one go
- Can happen anyway as part of committing transactions when using a circular log buffer

#### Write Ahead Logging
![](https://hackmd.io/_uploads/ry0VWq7Os.png =400x)

Typically used to implement UNDO/REDO (on 2PL based systems) or no-UNDO/REDO (on SI based systems)

- Separate persistent storage for data from persistent storage for the log
- Log records corresponding to a change in the database must be written to the log before changes to the data in the buffer cache are flushed to permanent storage

#### Checkpoints
![](https://hackmd.io/_uploads/SkO7M5XOi.png =400x)

Recovery happens from a checkpoint instead of from the beginning

- Push all dirty blocks to disk
- Push all the logs in the log buffer to disk
- Active transaction table, dirty page table (system state)
- Mark the log with a checkpoint label and flush it to the log

#### Recovery Procedure (ARIES Style Recovery)
![](https://hackmd.io/_uploads/B1tym97di.png =300x)

- Find the latest completed checkpoint in the log
- Traverse the log to the end analyzing what has been done:
    - Identify transactions that were active at the time of the crash
    - Identify dirty pages that might have not made it to the disk at the time of the crash
- Apply all updates (redo) starting from the log entry matching the lowest SCN in the dirty pages
- Undo all transactions that were active at the time of the crash