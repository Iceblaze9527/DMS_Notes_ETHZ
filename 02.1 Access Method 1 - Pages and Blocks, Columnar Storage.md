---
tags: DMS
---

# 02.1 Access Method 1: Pages and Blocks + Columnar Storage
[TOC]

## 1. Pages and Blocks
### 1.0 The notion of pages in a database
- **Hardware Page:** the atomic unit to write to storage
    - usually 4KB
- **OS Page:** the unit used by the OS to implement virtual memory
    - usually 4KB
- **Database Page:** a block, anywhere between 512B and 32 KB
    - Oracle 2KB to 32KB (typical 8KB)
    - MS SQL Server 8KB
    - MySQL 16KB
- Trend is towards larger block sizes (incurs less overhead in esp. OLAP)

### 1.1 Page / Block Structure
#### [Segment: Potential Bottleneck](https://hackmd.io/lQ8SgCAEQ86j9JNnWuLTTg#Segment-wise-Used-and-Free-List)

How these lists are implemented affects performance, which may create bottlenecks.
- Use several free lists so that concurrent transactions can look for free space in
parallel rather than conflict on access to the free list
- Make the traversal of the free list fast and keep the list small (shorter the larger the pages, sort the free list by available size, cache positions ...)
- Make sure holes can be efficiently found (store the available space in each page in incremental steps by using a small amount of bits)

#### [DB Page: Slotted Pages](https://hackmd.io/lQ8SgCAEQ86j9JNnWuLTTg?view#Block-Structure-Slotted-Pages)
![](https://hackmd.io/_uploads/SkoYNw47j.png =300x)

- Each page has a header (checksum, version, transaction visibility, compression information, utilization, etc.)
- Each tuple gets an tuple id (typically, block id + offset)
- The page maintains a list of the “slots” storing tuples in a page by storing a pointer (offset) to the beginning of each tuple

#### Why Slotted Pages
- To support variable length tuples
- Tuples get a permanent tuple id that does not change
- When data changes (e.g. database needs compaction):
    - If a tuple is modified and becomes larger, use the original space to store a pointer to the new location of the tuple (can be in another block)
    - If a tuple is deleted, just remove the pointer
    - If a tuple is modified and becomes smaller, just leave the unnecessary space empty
    - For insertion, look for a page with enough free space and compact the page if needed

#### [DB Page: Percentage Free](https://hackmd.io/lQ8SgCAEQ86j9JNnWuLTTg?view#Optimization---Percentage-Free-PCTFREE)
![](https://hackmd.io/_uploads/HJnwMDEms.png =300x)

To avoid the fragmentation that would occur if pages do not have enough space to modify a tuple that becomes larger.

#### [DB Page: Percentage Used](https://hackmd.io/lQ8SgCAEQ86j9JNnWuLTTg?view#Optimization---Percentage-Used-PCTUSED)
![](https://hackmd.io/_uploads/H1RkmvNmi.png =300x)

To avoid having to constantly move a block from the used list to the free list. Otherwise a block can constantly go from FREE to USED to FREE with single tuple deletes and inserts, adding overhead in managing the lists

### 1.2 Record Layout
#### Tuple Structure
![](https://hackmd.io/_uploads/rJXYrPV7o.png =300x)

- **Header:** validity flags for deletion, visibility info for concurrency control, bit map of null values, ...
- **Attributes:** Data for each non-null attribute (or a pointer to the data)

:::info
**Note:**
Relational engines do not store schema information in the tuple (types of the attributed are known), schema-less systems need to store the structure of the tuple since every one can be different
:::

#### Optimization
Pointer jumps are expensive when there are a lot of tuples!

![](https://hackmd.io/_uploads/BJu7LwNmo.png =200x)

Instead of length, store offsets. That way the record has a fixed sized part at the beginning and a varied sized part at the tail. Pointers point to tail of attribute. Each attribute can be accessed in constant time

![](https://hackmd.io/_uploads/SktOIDNQo.png =200x)

Reorder the attributes, place variable length data at the end. Better performance.

#### Corner Case: BLOBs (binary large object)
BLOBs are stored as sequential binary data, so database does not know how to operate on it.

#### Options for Corner Cases
- **Store as a BLOB on another block(s):** Accessible from the database but does not fit into a single block!
- **Store the name of a file where the BLOB is:** Does not take space on the database but will potentially lose data consistency!
    - Solution: integrate transaction file system to database!

## 2. Row vs Column Store
:::info
**Why Database Is Not on the GPU:**
- **Data Movement:** PCI bandwidth is too small
- **Irregular Computation:** joins and group-bys can be painful (need to store intermediate results)
:::

:::info
**Machine Learning:**
- Reduced precision of ML model cannot utilize such advantages on CPU! (usul. truncated down to int4 or int8, but CPU typically deals with int16!)
- Solution: specified Hardware designed to address this issue.
:::

### 2.1 Row Store / N-ary Storage Model (NSM)
![](https://hackmd.io/_uploads/By9EowEXs.png =600x)

> 03.3 “Data page layouts for relational databases on deep memory hierarchies”; The VLDB Journal, November 2002

- One cache miss per cacheline
- Row store is for OLTP

### 2.2 Column Store / Decomposition Storage Model (DSM)
![](https://hackmd.io/_uploads/HJa33DNXj.png =600x)

![](https://hackmd.io/_uploads/BJw9b4hms.png =600x)

> 03.3 “Data page layouts for relational databases on deep memory hierarchies”; The VLDB Journal, November 2002

- Column store is for OL-P

#### Vectorized Processing
![](https://hackmd.io/_uploads/HyB10D4io.png =600x)

- Modern processors heavily use vectorized processing (like [Simple Instruction Multiple Data (SIMD)](https://www.wikiwand.com/en/Single_instruction,_multiple_data) and [Advanced Vector Extensions (AVX)](https://www.wikiwand.com/en/Advanced_Vector_Extensions)) to speed things up
- A column store presents the data exactly in the vectorized representation so that it can exploit vectorized processing
- Very useful for numeric values and bit comparisons

### 2.3 Hybrid: Partition Attributes Across (PAX)
![](https://hackmd.io/_uploads/SJLfqZnQj.png =600x)

![](https://hackmd.io/_uploads/SyLZA-hms.png =300x)

> 03.3 “Data page layouts for relational databases on deep memory hierarchies”; The VLDB Journal, November 2002

- No Record Header or LogicalID
- Hybrid store is for OLAP

#### Motivation
- **Changing Hardware:** 
    - at that time the bottleneck shifted to caches, and column store increases cache locality significantly; 
    - also, I/O limit cannot be ignored 
    - so there has to be compromise between row store and column store
- **The Emergence of OLAP and Cloud:** 
    - OLAP systems like Snowflake have big blocks which address network bandwidth issues and mitigate the issues with wide tables (too many columns to pack into one page)
    - can leverage indexing

#### Disadvantages:
- **More Complex Page Structure:** PAX makes tuple reconstruction easier but space management is far more complex due to the mini-page layout
    - Need to maintain `percentage_used` and `percentage_free` for each minipage
    - Utilization rate issues

## 3. The Design and Implementation of Columnar Storage
### 3.1 Projection
In C-Store, we use the notation (saleid,date,region|date) to indicate a projection of the sales table containing saleid, date and region attributes sorted by date. 

Note that these projections contain dierent columns, and neither contains all of the columns in the table.

### 3.2 Compression
Compression is not used to save space but to save **bandwidth**
- memory bandwidth
- network bandwidth in cloud setting (to save computing resources)

Modern Solution:
- process data in compressed form
- smart hardware for cloud: use hardware to compress the data

#### Run Length Encoding (RLE)
If a value appears repeated many times, just store it once and how many times it appears

For example, if the first 42 elements of a column contain the value ‘M’, then these 42 elements can be replaced with the triple: (‘M’, 1, 42).

Useful for attributes with low cardinality (e.g., departments)

Can compress the data significantly but makes processing more difficult and makes the encoding variable in size

#### Bitmaps / Bit Vector Encoding
![](https://hackmd.io/_uploads/Sy8mPKSoi.png =200x)

For every value that an attribute might take, construct a bitmap as follows:
- Create an array as long as the number of tuples
- If tuple `i` has value `x` for that attribute, position `i` in the bitmap `x` is set to `1`

Bit-vector encoding is most useful when columns have a limited number of possible data values. However, it can be used even for columns with a large number of values if the bit-vectors are further compressed using run length encoding.

Bitmaps act as an **index** and can be used to process queries just by looking at the bitmap

overhead: 
- more space
- for sparse repr: makes query processing slightly more complicated

#### Dictionary Compression
Widely used in almost all the systems
- Build a dictionary mapping long entries to, e.g., integers or small numbers
- Can be applied to any finite collection of variable-length attributes (e.g., departments, cantons, provinces within a country, etc.)
- Dictionary automatically built when data is loaded
- Data can be processed in compressed form (it is encoded rather than compressed)
- dictionary used for query rewrite and result rewrite

#### Frame of Reference (FOR) / Delta Encoding
Many attributes have value locality, they can be represented as a delta over some base. The physical representation of a block of FOR values is the base followed by one small integer for each tuple. 

![](https://hackmd.io/_uploads/rkBf-5Hos.png =400x)

### 3.3 Late Materialization
In a column-store that uses late materialization, the predicates are applied to the column for each attribute separately, and a list of positions (ordinal osets within a column) of values that passed the predicates are produced.

![](https://hackmd.io/_uploads/B1pZv5Sjo.png =600x)

Figure 4.1 shows a simple example of a late material-
ization query plan and execution in a modern column-store. Here, we assume that intermediate results are represented with position lists. 

The query in Figure 4.1 is a select-project-join query; it essentially filters three columns of two separate tables (R,S) and then joins these two tables on two columns, while subsequently it performs a sum aggregation on one of the tables (R). 

Figure 4.1 shows graphically the various steps performed to answer this query, as well as it shows the query plan in MAL algebra and how each MAL operator behaves.

### 3.4 Joins
The output of the join is a set of pairs of positions in the two input relations for which the predicate succeeded. 

![](https://hackmd.io/_uploads/SyZNy9Hoo.png =400x)

For many join algorithms, the output positions for the left (outer) input relation will be sorted while the output positions of the right (inner) input relation will not. This is because the positions in the left column are often iterated through in order, while the right relation is probed for join predicate matches. 

For other join algorithms (for ex- ample, algorithms that sort or repartition both sets of input) neither position list will be sorted. 

Either way, at least one set of output po- sitions will not be sorted.

### 3.5 Database Cracking (Adaptive Indexing)
![](https://hackmd.io/_uploads/SJ7bz5ris.png =600x)

Assume a query requests `A < 10`. In response, a cracking DBMS clusters all tuples of A with `A < 10` at the beginning of the respective column C, while pushing all tuples with `A ≥ 10` to the end. A subsequent query requesting `A ≥ v1`, where `v1 ≥ 10`, has to search and crack only the last part of C where values `A ≥ 10` reside. Likewise, a query that requests `A < v2`, where `v2 ≤ 10`, searches and cracks only the first part of C. All crack actions happen as part of the query operators, requiring no external administration. 
